{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pinecone\n",
    "from pinecone import Pinecone\n",
    "import json\n",
    "\n",
    "\n",
    "# Function to search MCQs based on user query across multiple namespaces\n",
    "def search_mcqs_by_query(index, query, namespaces, top_k=50):\n",
    "    \"\"\"\n",
    "    Searches for MCQs across multiple namespaces and returns the best matches.\n",
    "    \"\"\"\n",
    "    model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    query_embedding = model.encode(query)\n",
    "    all_results = []\n",
    "\n",
    "    for namespace in namespaces:\n",
    "        try:\n",
    "            response = index.query(vector=query_embedding.tolist(), namespace=namespace, top_k=top_k, include_metadata=True)\n",
    "            for match in response[\"matches\"]:\n",
    "                all_results.append({\n",
    "                    \"id\": match[\"id\"],\n",
    "                    \"metadata\": match[\"metadata\"],\n",
    "                    \"score\": match[\"score\"],\n",
    "                    \"namespace\": namespace\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching namespace '{namespace}': {e}\")\n",
    "\n",
    "    # Sort all results by score in descending order\n",
    "    all_results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    \n",
    "    \n",
    "    return all_results[:top_k]  # Return top_k best matches across all namespaces\n",
    "\n",
    "\n",
    "# Function to generate a quiz using ChatGroq (LLaMA model)\n",
    "def generate_quiz_with_groq(llm, retrieved_data, query, num_questions):\n",
    "    \"\"\"\n",
    "    Generates a quiz using the LLM, allowing augmentation beyond the retrieved data.\n",
    "    \"\"\"\n",
    "    # Format the retrieved data into a usable string format\n",
    "    formatted_mcqs = \"\"\n",
    "    for mcq in retrieved_data['mcqs']:\n",
    "        formatted_mcqs += f\"\"\"\n",
    "        {{\n",
    "            \"question_no\": \"{mcq['question_no']}\",\n",
    "            \"question_text\": \"{mcq['question_text']}\",\n",
    "            \"question_img_link\": \"{mcq['question_img_link']}\",\n",
    "            \"options\": {mcq['options']},\n",
    "            \"correct_option\": \"{mcq['correct_option']}\",\n",
    "            \"topic\": \"{mcq['topic']}\"\n",
    "        }},\n",
    "        \"\"\"\n",
    "    \n",
    "    groq_prompt = f\"\"\"\n",
    "    Based on the following retrieved MCQ data, create a quiz with exactly {num_questions} multiple-choice questions.\n",
    "    Align the quiz with the user query: \"{query}\". \n",
    "    Use the provided MCQs as much as possible, but if necessary, generate additional relevant questions to complete the quiz. Ensure that all questions are relevant and derived from the retrieved data.\n",
    "\n",
    "    The retrieved MCQs are as follows:\n",
    "    {formatted_mcqs}\n",
    "    Instructions:\n",
    "    1. Rewrite or enhance questions if needed to ensure clarity, conciseness, and relevance.\n",
    "    2. Ensure all questions are formatted consistently in terms of structure and wording.\n",
    "    Please return the quiz in the following exact JSON format starting from json format without any line in starting and '''json string:\n",
    "    {{\n",
    "        \"quiz_title\": \"CPU Scheduling Quiz\",\n",
    "        \"quiz_description\": \"A quiz on CPU Scheduling algorithms and concepts\",\n",
    "        \"questions\": [\n",
    "            {{\n",
    "                \"question_no\": \"Question49\",\n",
    "                \"question_text\": \"The question text here\",\n",
    "                \"question_img_link\": \"The image URL\",\n",
    "                \"options\": [\n",
    "                    {{\n",
    "                        \"option\": \"Option A\",\n",
    "                        \"is_correct\": true\n",
    "                    }},\n",
    "                    {{\n",
    "                        \"option\": \"Option B\",\n",
    "                        \"is_correct\": false\n",
    "                    }},\n",
    "                    {{\n",
    "                        \"option\": \"Option C\",\n",
    "                        \"is_correct\": false\n",
    "                    }},\n",
    "                    {{\n",
    "                        \"option\": \"Option D\",\n",
    "                        \"is_correct\": false\n",
    "                    }}\n",
    "                ],\n",
    "                \"correct_answer\": \"The correct answer\",\n",
    "                \"correct_answer_explanation\": \"Explanation for the correct answer\",\n",
    "                \"topic\": \"Cpu Scheduling\"\n",
    "            }},\n",
    "            ...\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the response from the LLaMA model\n",
    "    response = llm.invoke(groq_prompt)\n",
    "\n",
    "    # Try to parse the response content as JSON\n",
    "    return clean_response(response.content)\n",
    "    \n",
    "\n",
    "\n",
    "# Function to integrate Pinecone query with quiz generation\n",
    "def generate_quiz_from_pinecone(query, namespaces, top_k=50, num_questions=10):\n",
    "    \"\"\"\n",
    "    Generates a quiz using data retrieved from Pinecone, aligned with the query and user constraints.\n",
    "    \"\"\"\n",
    "    # Initialize Pinecone\n",
    "    pc = Pinecone(api_key=\"pcsk_3CYnJi_TZbGr8CeCcVxAsz4Li7J5n5hNBRqM7PA7k6xGKx7ftNXUYMYUJLJcb3PZrTneH4\", environment=\"us-west1-gcp\")\n",
    "    index_name = \"mcq-index\"\n",
    "    index = pc.Index(index_name)\n",
    "    \n",
    "    # Retrieve the MCQs based on the user query\n",
    "    mcq_results = search_mcqs_by_query(index, query, namespaces, top_k)\n",
    "    if not mcq_results:\n",
    "        return \"No MCQs found for the given query.\"\n",
    "\n",
    "    # Convert retrieved MCQ data into a structured JSON format\n",
    "    retrieved_mcqs = []\n",
    "    for match in mcq_results:\n",
    "        metadata = match[\"metadata\"]\n",
    "        retrieved_mcqs.append({\n",
    "            \"topic\": metadata.get(\"topic\"),\n",
    "            \"question_no\": metadata.get(\"question_no\"),\n",
    "            \"question_text\": metadata.get(\"question_text\"),\n",
    "            \"question_img_link\": metadata.get(\"question_img_link\"),\n",
    "            \"options\": metadata.get(\"options\"),\n",
    "            \"correct_option\": metadata.get(\"correct_option\")\n",
    "        })\n",
    "\n",
    "    # Convert retrieved data into a JSON-like string for LLM\n",
    "    retrieved_data = {\n",
    "        \"query\": query,\n",
    "        \"mcqs\": retrieved_mcqs\n",
    "    }\n",
    "\n",
    "    # Initialize ChatGroq LLM\n",
    "    llm = ChatGroq(\n",
    "        temperature=0,\n",
    "        groq_api_key=\"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\",  # Replace with your actual API key\n",
    "        model_name=\"llama-3.1-70b-versatile\"\n",
    "    )\n",
    "    \n",
    "    # Generate quiz using ChatGroq\n",
    "    return generate_quiz_with_groq(llm, retrieved_data, query, num_questions)\n",
    "    \n",
    "\n",
    "\n",
    "# Example usage\n",
    "query = input(\"Enter your search query: \")\n",
    "namespaces = [\"computer_organization\", \"operating_system\"]  # Add or modify namespaces as needed\n",
    "top_k = 30  # Default value for maximum results to retrieve\n",
    "num_questions = int(input(\"Enter the number of MCQs you want in the quiz: \"))\n",
    "\n",
    "# Generate quiz based on user query\n",
    "quiz = generate_quiz_from_pinecone(query, namespaces, top_k, num_questions)\n",
    "print(quiz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_response(response):\n",
    "    # Clean up any unwanted characters (e.g., leading non-JSON content)\n",
    "    cleaned_response = response.lstrip()  # Removes any leading whitespace\n",
    "\n",
    "    # Check for and remove unwanted introductory text\n",
    "    if cleaned_response.startswith(\"Here is the quiz\"):\n",
    "        # Find the index of the start of the actual JSON part\n",
    "        json_start_index = cleaned_response.find(\"{\")\n",
    "        cleaned_response = cleaned_response[json_start_index:].lstrip()\n",
    "\n",
    "    # Remove the \"```json\" if it exists at the start of the response\n",
    "    if cleaned_response.startswith(\"```json\"):\n",
    "        cleaned_response = cleaned_response[len(\"```json\"):].lstrip()\n",
    "\n",
    "    # Check if the cleaned response starts with a valid JSON object (i.e., '{')\n",
    "    if cleaned_response.startswith(\"{\"):\n",
    "        try:\n",
    "            # Parse the cleaned-up JSON and return as a Python dictionary (not a string)\n",
    "            parsed_response = json.loads(cleaned_response)\n",
    "            return parsed_response  # Return the parsed JSON (as a Python dictionary)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON: {e}\")\n",
    "            print(\"Cleaned Response:\", cleaned_response)\n",
    "            return None\n",
    "    else:\n",
    "        print(\"The cleaned response doesn't start with a valid JSON object.\")\n",
    "        print(\"Cleaned Response:\", cleaned_response)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(quiz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
